{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "num train: 39774 ; num test: 9944\n",
      "building vocabulary...\n",
      "size of vocabulary: 7137\n",
      "building label set...\n",
      "size of label set: 20\n",
      "processing train data...\n",
      "processing test data...\n",
      "processing labels...\n",
      "processing done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class DataManager(object):\n",
    "    '''\n",
    "    read data and return json object\n",
    "    '''\n",
    "    def load_data(self, train_file, test_file):\n",
    "        train_data = self.__read_data(train_file)\n",
    "        test_data = self.__read_data(test_file)\n",
    "        train_num = len(train_data)\n",
    "        test_num = len(test_data)\n",
    "        print 'data loaded'\n",
    "        print 'num train:',train_num,'; num test:',test_num\n",
    "        return train_data,test_data\n",
    "    \n",
    "    '''\n",
    "    turn data into Bag-of-Words vectors and labels into one-hot vectors\n",
    "    '''\n",
    "    def process_data(self,train_data,test_data):\n",
    "        print 'building vocabulary...'\n",
    "        vocab = self.__build_vocab(train_data,test_data)\n",
    "        print 'building label set...'\n",
    "        label_set = self.__build_labels(train_data)\n",
    "        print 'processing train data...'\n",
    "        train_data_vec = self.__to_BoW(train_data,u'ingredients',vocab)\n",
    "        print 'processing test data...'\n",
    "        test_data_vec = self.__to_BoW(test_data,u'ingredients',vocab)\n",
    "        print 'processing labels...'\n",
    "        train_label_vec = self.__to_BoW(train_data,u'cuisine',label_set)\n",
    "        print 'processing done'\n",
    "        return train_data_vec, train_label_vec, test_data_vec, vocab, label_set\n",
    "    \n",
    "    def __read_data(self,file_path):\n",
    "        if not os.path.isfile(file_path):\n",
    "            print 'file not found:',file_path\n",
    "            exit(-1)\n",
    "        data = json.loads(open(file_path).read())\n",
    "        return data\n",
    "    \n",
    "    def __build_vocab(self,train_data,test_data):\n",
    "        vocab = set()\n",
    "        train_num = len(train_data)\n",
    "        test_num = len(test_data)\n",
    "        for i in range(train_num):\n",
    "            ingredients = train_data[i][u'ingredients']\n",
    "            for ingrd in ingredients:\n",
    "                vocab.add(ingrd)\n",
    "        for i in range(test_num):\n",
    "            ingredients = test_data[i][u'ingredients']\n",
    "            for ingrd in ingredients:\n",
    "                vocab.add(ingrd)\n",
    "        vocab = list(vocab)\n",
    "        sorted(vocab)\n",
    "        print 'size of vocabulary:',len(vocab)\n",
    "        return vocab\n",
    "    \n",
    "    def __build_labels(self,train_data):\n",
    "        label_set = set()\n",
    "        train_num = len(train_data)\n",
    "        for i in range(train_num):\n",
    "            label_set.add(train_data[i][u'cuisine'])\n",
    "        label_set = list(label_set)\n",
    "        sorted(label_set)\n",
    "        print 'size of label set:',len(label_set)\n",
    "        return label_set\n",
    "    \n",
    "    def __to_BoW(self,data,key,vocab):\n",
    "        num_data = len(data)\n",
    "        num_vocab = len(vocab)\n",
    "        data_vec = []\n",
    "        for i in range(num_data):\n",
    "            vec = np.zeros(num_vocab,dtype=int)\n",
    "            items = data[i][key]\n",
    "            if type(items) != type(list()):\n",
    "                vec[vocab.index(items)] = 1\n",
    "            else:\n",
    "                for item in items:\n",
    "                    vec[vocab.index(item)] = 1\n",
    "            data_vec.append(vec)\n",
    "        return data_vec\n",
    "        \n",
    "    \n",
    "def main():\n",
    "    trainPath = '../data/train.json'\n",
    "    testPath = '../data/test.json'\n",
    "    dm = DataManager()\n",
    "    train_data, test_data = dm.load_data(trainPath,testPath)\n",
    "    train_data_vec, train_label_vec, test_data_vec, vocabulary, label_set = dm.process_data(train_data,test_data)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
