1. What we have done

- Neural Network:
we use a neural network with three fully connected hidden layer, and each hidden layer is followed by a dropout layer. A softmax layer is appended as the output layer to generate the prediction probabilities. We use the batched gradient descent with momentum to learn the network parameters. The sizes of the fully connected layers are 1000-500-100. The learning rate is 0.01, with a decay of 10e-6, and the momentum is 0.9.

The test accuracy is 79.224 if we use the Bag-of-Words features as input, we also tried the TF-IDF features with the same network setting but the accuracy drops to 77.916.

2. What to be done
- Neural Network:
(a) Modify the network and tune the parameters to get higher accuracy. 
(b) Try adding batch normalization. 
(c) 

3. What has changed 

(a) We are not using the class-based association rule mining algorithm, since it is out-dated and not used as a popular algorithm.
